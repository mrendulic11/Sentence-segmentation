{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdAiv40LkmpQawobc1Cyzg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>\n","\n","# Natural language processing\n","## Project - Sentence segmentation\n","## Model testing\n","\n","### 2023./2024.\n","## Matea Kunac, Marijana RenduliÄ‡\n","</center>"],"metadata":{"id":"-9iyqtpgTG3i"}},{"cell_type":"markdown","source":["# 1. Introduction"],"metadata":{"id":"FLeQBJpP-DZ9"}},{"cell_type":"markdown","source":["This notebook focuses on the model testing."],"metadata":{"id":"_PplCw20-FKa"}},{"cell_type":"markdown","source":["#2. Code"],"metadata":{"id":"LQy6tWgH-J5b"}},{"cell_type":"markdown","source":["##Libraries"],"metadata":{"id":"XvvzKIgZ-LvT"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4QYaWkMXTLVK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708615206461,"user_tz":-60,"elapsed":32955,"user":{"displayName":"Marijana","userId":"13940462459037984967"}},"outputId":"47e8ae5f-4d63-48fb-c81a-d879defafa5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMC1YaH-S-6-"},"outputs":[],"source":["import torch\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pickle\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"markdown","source":["##Functions"],"metadata":{"id":"Q6JRba8D-Obf"}},{"cell_type":"code","source":["class TextChunkDataset(Dataset):\n","    \"\"\"\n","    Loads data chunks and their corresponding labels from specified pickle files\n","    \"\"\"\n","    def __init__(self, chunks_file, labels_file):\n","        with open(chunks_file, 'rb') as f:\n","            self.chunks = pickle.load(f)\n","        with open(labels_file, 'rb') as f:\n","            self.labels = pickle.load(f)\n","\n","    def __len__(self):\n","        return len(self.chunks)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.chunks[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.float32)"],"metadata":{"id":"_vKuMYG4TNAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad_collate(batch):\n","    \"\"\"\n","    Pads sequences to match the longest sequence in a batch\n","    \"\"\"\n","    (xx, yy) = zip(*batch)\n","\n","    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n","\n","    yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n","\n","    return xx_pad, yy_pad"],"metadata":{"id":"tj_XGFvpTQNW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def evaluate(model, data_loader):\n","    \"\"\"\n","    A function to evaluate the model's performance on a given dataset.\n","    It switches the model to evaluation mode, computes predictions for the dataset,\n","    and calculates evaluation metrics such as accuracy, precision, recall, and F1 score.\n","    \"\"\"\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for chunks, labels in data_loader:\n","            chunks, labels = chunks.to(device), labels.to(device)\n","            outputs = model(chunks).squeeze(-1)\n","            predicted = torch.round(torch.sigmoid(outputs))\n","\n","            all_predictions.extend(predicted.view(-1).cpu().numpy())\n","            all_labels.extend(labels.view(-1).cpu().numpy())\n","\n","    all_predictions = np.array(all_predictions)\n","    all_labels = np.array(all_labels)\n","\n","    accuracy = 100 * (all_predictions == all_labels).mean()\n","    precision = precision_score(all_labels, all_predictions)\n","    recall = recall_score(all_labels, all_predictions)\n","    f1 = f1_score(all_labels, all_predictions)\n","\n","    return accuracy, precision, recall, f1"],"metadata":{"id":"gsh21xMvYB2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiLayerBiGRUModel(nn.Module):\n","    \"\"\"\n","    multi-layer Bidirectional GRU architecture\n","\n","    The model consists of the following components:\n","    - Embedding Layer: Converts input tokens into dense vectors of a specified size (embedding_dim)\n","    - Multi-Layer BiGRU: Processes the embedded input sequentially in both forward and backward directions across multiple layers (num_layers)\n","    - Fully Connected (Linear) Layer: Transforms the BiGRU's output to the desired output dimension (output_dim)\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=1, num_layers=3):\n","        super(MultiLayerBiGRUModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Times 2 because it's bidirectional\n","\n","    def forward(self, text):\n","        embedded = self.embedding(text)\n","        output, hidden = self.gru(embedded)\n","        final_output = self.fc(output)\n","        return final_output"],"metadata":{"id":"0AbUFTeKZMam"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Data loading"],"metadata":{"id":"OvPVne6F-RtD"}},{"cell_type":"code","source":["test_dataset = TextChunkDataset('/content/drive/MyDrive/Sentence_segmentation_popravak/data/test_encoded_chunks.pkl', '/content/drive/MyDrive/Sentence_segmentation_popravak/data/test_encoded_labels.pkl')\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=pad_collate)"],"metadata":{"id":"zuHMz5E8TR7A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Model testing"],"metadata":{"id":"k2ImZIs7-d8b"}},{"cell_type":"code","source":["def load_pickle(file_path):\n","    \"\"\"\n","    Load and return the contents of a pickle file.\n","    \"\"\"\n","    with open(file_path, 'rb') as f:\n","        return pickle.load(f)\n","\n","vocab = load_pickle('/content/drive/MyDrive/Sentence_segmentation_popravak/data/vocab.pkl')\n","# Model parameters\n","vocab_size = len(vocab) + 1\n","embedding_dim = 100\n","hidden_dim = 128"],"metadata":{"id":"1HcqeihLYUd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model\n","model = MultiLayerBiGRUModel(vocab_size, embedding_dim, hidden_dim)\n","\n","model_path = '/content/drive/MyDrive/Sentence_segmentation_popravak/models/best_model_epoch_12_f1_0.90.pth'\n","model.load_state_dict(torch.load(model_path))\n","\n","# Move model to the appropriate device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esy8ccIIde57","executionInfo":{"status":"ok","timestamp":1708617750890,"user_tz":-60,"elapsed":388,"user":{"displayName":"Marijana","userId":"13940462459037984967"}},"outputId":"44f44204-d1c2-4dbc-c031-959e7971346a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiLayerBiGRUModel(\n","  (embedding): Embedding(58375, 100)\n","  (gru): GRU(100, 128, num_layers=3, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader)\n","print(f'Accuracy on test set: {test_accuracy:.2f}%')\n","print(f'Precision on test set: {test_precision:.2f}')\n","print(f'Recall on test set: {test_recall:.2f}')\n","print(f'F1 Score on test set: {test_f1:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwaYqrSHX9iQ","executionInfo":{"status":"ok","timestamp":1708617761784,"user_tz":-60,"elapsed":6954,"user":{"displayName":"Marijana","userId":"13940462459037984967"}},"outputId":"f91cd70e-bdf4-4471-e14a-f82a8872d114"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test set: 99.38%\n","Precision on test set: 0.96\n","Recall on test set: 0.88\n","F1 Score on test set: 0.92\n"]}]},{"cell_type":"code","source":["def print_labels_predictions(model, data_loader):\n","    \"\"\"\n","    Evaluates a trained model on a given dataset and prints the actual and predicted labels for comparison\n","    \"\"\"\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for chunks, labels in data_loader:\n","            chunks, labels = chunks.to(device), labels.to(device)\n","            outputs = model(chunks).squeeze(-1)\n","            predicted = torch.round(torch.sigmoid(outputs))\n","\n","            all_predictions.extend(predicted.view(-1).cpu().numpy())\n","            all_labels.extend(labels.view(-1).cpu().numpy())\n","\n","    all_predictions = np.array(all_predictions)\n","    all_labels = np.array(all_labels)\n","\n","    print(\"Actual Labels:\", all_labels)\n","    print(\"Predicted Labels:\", all_predictions)\n","\n","print_labels_predictions(model, test_loader)"],"metadata":{"id":"2LHuHgYvfOEU","executionInfo":{"status":"ok","timestamp":1708618592553,"user_tz":-60,"elapsed":2926,"user":{"displayName":"Marijana","userId":"13940462459037984967"}},"outputId":"3a9cb021-f132-4146-aea6-3dcb951bf254","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual Labels: [1. 0. 0. ... 0. 0. 0.]\n","Predicted Labels: [1. 0. 0. ... 0. 0. 0.]\n"]}]}]}